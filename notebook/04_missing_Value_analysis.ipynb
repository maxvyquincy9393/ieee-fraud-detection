{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 - Missing Value Analysis\n",
                "\n",
                "## Context\n",
                "In fraud detection datasets, missingness is rarely random. The IEEE-CIS data exhibits complex patterns where missing values often correlate with transaction characteristics and fraud outcomes. Understanding these patterns is essential before choosing imputation strategies.\n",
                "\n",
                "## Objective\n",
                "- Quantify missingness across all feature groups\n",
                "- Analyze the correlation between missingness and fraud outcomes\n",
                "- Identify feature-level and row-level missingness patterns\n",
                "- Develop imputation strategy recommendations\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# IMPORT & LOAD\n",
                "# ============================================================================\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "train = pd.read_parquet(Path('../data/interim/train_merged.parquet'))\n",
                "print(f'Data loaded: {train.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# OVERALL MISSING VALUE SUMMARY\n",
                "# ============================================================================\n",
                "\n",
                "missing = train.isnull().sum()\n",
                "missing_pct = (missing / len(train) * 100).sort_values(ascending=False)\n",
                "\n",
                "# Filter to columns with missing values\n",
                "cols_missing = missing_pct[missing_pct > 0]\n",
                "\n",
                "print('Missing Overview:')\n",
                "print(f'   Total Columns: {len(train.columns)}')\n",
                "print(f'   Columns with missing: {len(cols_missing)} ({len(cols_missing) / len(train.columns)*100:.1f}%)')\n",
                "print(f'   0% missing: {(missing_pct == 0).sum()} columns')\n",
                "print(f'   1-10% missing: {((missing_pct > 0) & (missing_pct <= 10)).sum()} columns')\n",
                "print(f'   10-50% missing: {((missing_pct > 10) & (missing_pct <= 50)).sum()} columns')\n",
                "print(f'   50-90% missing: {((missing_pct > 50) & (missing_pct <= 90)).sum()} columns')\n",
                "print(f'   >90% missing: {(missing_pct > 90).sum()} columns')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Missingness Distribution Patterns\n",
                "\n",
                "From the result we can see structured missingness patterns that are informative:\n",
                "\n",
                "- **Majority of columns have missing values** - this is common in fraud datasets where data collection varies by channel\n",
                "- **Tiered distribution** - clear separation between low, medium, and high missingness columns\n",
                "- **Very high missingness (>90%)** columns may be candidates for removal unless they carry strong signal\n",
                "\n",
                "**Key insight**: The distribution of missingness helps us categorize columns into different imputation strategies rather than applying one-size-fits-all approach.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# MISSING BY COLUMN GROUP\n",
                "# ============================================================================\n",
                "\n",
                "col_group = {\n",
                "    'Core': ['TransactionId', 'isFraud', 'TransactionDT', 'TransactionAmt', 'ProductCD'],\n",
                "    'Card': [c for c in train.columns if c.startswith('card')],\n",
                "    'Address': ['addr1', 'addr2', 'dist1', 'dist2'],\n",
                "    'Email': ['P_emaildomain', 'R_emaildomain'],\n",
                "    'C (Count)': [c for c in train.columns if c.startswith('C') and c[1:].isdigit()],\n",
                "    'D (Timedelta)': [c for c in train.columns if c.startswith('D') and c[1:].isdigit()],\n",
                "    'M (Match)': [c for c in train.columns if c.startswith('M') and c[1:].isdigit()],\n",
                "    'V (Vesta)': [c for c in train.columns if c.startswith('V') and c[1:].isdigit()],\n",
                "    'Identity': [c for c in train.columns if c.startswith('id_') or c in ['DeviceType', 'DeviceInfo']]\n",
                "}\n",
                "\n",
                "print('Average Missing Rate by Feature Group:')\n",
                "for name, cols in col_group.items():\n",
                "    valid_cols = [c for c in cols if c in train.columns]\n",
                "    if valid_cols:\n",
                "        avg_missing = train[valid_cols].isna().mean().mean() * 100\n",
                "        print(f'   {name}: {avg_missing:.1f}%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Group-wise Missingness Patterns\n",
                "\n",
                "From the result we identify distinct patterns by feature group:\n",
                "\n",
                "- **Core features**: Zero or minimal missingness - these are always collected\n",
                "- **Identity features**: High missingness (~75%) - only collected for subset of transactions\n",
                "- **V (Vesta) features**: Variable missingness with block-wise patterns\n",
                "- **C/D features**: Generally lower missingness, more complete\n",
                "\n",
                "**Strategy**: Group correlated missingness patterns into single indicator features to reduce dimensionality while preserving the signal.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZE MISSING PATTERN - TOP 30 COLUMNS\n",
                "# ============================================================================\n",
                "\n",
                "top_missing = missing_pct.head(30)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "top_missing.plot(kind='barh', ax=ax, color='steelblue')\n",
                "ax.set_title('Top 30 Columns by Missing Percentage', fontsize=14)\n",
                "ax.set_xlabel('Missing (%)')\n",
                "ax.axvline(x=50, color='red', linestyle='--', label='50% Threshold')\n",
                "ax.axvline(x=75, color='orange', linestyle='--', label='75% Threshold')\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Top Missing Columns Visualization\n",
                "\n",
                "From the visualization we observe:\n",
                "\n",
                "- **Identity features dominate** the top missing columns (id_XX, DeviceInfo, DeviceType)\n",
                "- **Clear threshold patterns** - many columns cluster around 75-76% missing (identity coverage)\n",
                "- **V-features** also appear with high missingness in certain blocks\n",
                "\n",
                "**Decision point**: Columns above 75% threshold should be carefully evaluated - keep only if they provide strong fraud signal despite high missingness.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# FRAUD RATE: MISSING VS PRESENT\n",
                "# ============================================================================\n",
                "\n",
                "results = []\n",
                "\n",
                "for col in cols_missing.index[:30]:\n",
                "    mask_missing = train[col].isnull()\n",
                "    \n",
                "    fraud_missing = train.loc[mask_missing, 'isFraud'].mean() * 100\n",
                "    fraud_present = train.loc[~mask_missing, 'isFraud'].mean() * 100\n",
                "    \n",
                "    results.append({\n",
                "        'column': col,\n",
                "        'missing_pct': missing_pct[col],\n",
                "        'fraud_missing': fraud_missing,\n",
                "        'fraud_present': fraud_present,\n",
                "        'fraud_diff': fraud_missing - fraud_present\n",
                "    })\n",
                "\n",
                "missing_fraud_df = pd.DataFrame(results)\n",
                "print('Fraud Rate: Missing vs Present')\n",
                "print(missing_fraud_df.sort_values('fraud_diff', ascending=False).head(15).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Missingness Predicts Fraud\n",
                "\n",
                "From the result we discover that **missingness is predictive of fraud**:\n",
                "\n",
                "- Some features show significant fraud rate difference between missing and present values\n",
                "- Positive `fraud_diff` means fraud is **higher** when value is missing\n",
                "- Negative `fraud_diff` means fraud is **lower** when value is missing\n",
                "\n",
                "**Actionable recommendation**: For any feature with >10% missing that shows fraud correlation, create a binary `{feature}_missing` indicator before any imputation. This preserves valuable signal that would otherwise be lost.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZE FRAUD RATE BY MISSING STATUS\n",
                "# ============================================================================\n",
                "\n",
                "top_diff = missing_fraud_df.nlargest(10, 'fraud_diff')\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "x = range(len(top_diff))\n",
                "width = 0.35\n",
                "\n",
                "ax.bar([i - width/2 for i in x], top_diff['fraud_present'], width, label='Present', color='#2ecc71')\n",
                "ax.bar([i + width/2 for i in x], top_diff['fraud_missing'], width, label='Missing', color='#e74c3c')\n",
                "\n",
                "ax.set_xticks(list(x))\n",
                "ax.set_xticklabels(top_diff['column'], rotation=45, ha='right')\n",
                "ax.set_ylabel('Fraud Rate (%)')\n",
                "ax.set_title('Fraud Rate: Missing vs Present (Top 10 Difference)', fontsize=14)\n",
                "ax.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Visual Confirmation of Missing Value Signal\n",
                "\n",
                "The bar chart clearly shows:\n",
                "\n",
                "- **Red bars (missing) vs Green bars (present)** highlight the fraud rate gap\n",
                "- Columns with larger gaps are more valuable as missingness indicators\n",
                "- This visual helps prioritize which `_missing` features to create\n",
                "\n",
                "**Feature Engineering Tip**: Create missingness indicators only for columns where the gap is statistically significant (>1-2% difference) to avoid feature bloat.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# IMPUTATION STRATEGY RECOMMENDATION\n",
                "# ============================================================================\n",
                "\n",
                "def get_imputation_strategy(col, missing_pct, dtype):\n",
                "    \"\"\"Recommend imputation strategy based on missing % and dtype\"\"\"\n",
                "    if missing_pct == 0:\n",
                "        return 'None needed'\n",
                "    elif missing_pct > 95:\n",
                "        return 'Drop column'\n",
                "    elif missing_pct > 75:\n",
                "        return 'Indicator only (too much missing)'\n",
                "    elif dtype == 'object':\n",
                "        return 'Mode + Indicator'\n",
                "    elif dtype in ['float64', 'float32', 'int64', 'int32']:\n",
                "        if missing_pct < 10:\n",
                "            return 'Median'\n",
                "        else:\n",
                "            return 'Median + Indicator'\n",
                "    else:\n",
                "        return 'Constant (-999)'\n",
                "\n",
                "# Generate recommendations\n",
                "recommendations = []\n",
                "for col in train.columns:\n",
                "    pct = missing_pct.get(col, 0)\n",
                "    dtype = str(train[col].dtype)\n",
                "    strategy = get_imputation_strategy(col, pct, dtype)\n",
                "    \n",
                "    recommendations.append({\n",
                "        'column': col,\n",
                "        'missing_pct': pct,\n",
                "        'dtype': dtype,\n",
                "        'strategy': strategy\n",
                "    })\n",
                "\n",
                "rec_df = pd.DataFrame(recommendations)\n",
                "\n",
                "print('Imputation Strategy Summary:')\n",
                "print(rec_df['strategy'].value_counts().to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Insight: Imputation Strategy Distribution\n",
                "\n",
                "The recommended strategies break down as follows:\n",
                "\n",
                "- **None needed**: Complete columns requiring no imputation\n",
                "- **Median / Median + Indicator**: Numeric columns with varying missingness\n",
                "- **Mode + Indicator**: Categorical columns\n",
                "- **Indicator only**: Very high missingness where imputing values adds noise\n",
                "- **Drop column**: Columns with >95% missing that provide no signal\n",
                "\n",
                "**Important**: Always compute imputation statistics (median, mode) on training data only to prevent data leakage.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# SAVE RECOMMENDATIONS TO CSV\n",
                "# ============================================================================\n",
                "\n",
                "output_path = Path('../data/metadata/missing_value_report.csv')\n",
                "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "rec_df.to_csv(output_path, index=False)\n",
                "\n",
                "print(f'Saved recommendations to: {output_path}')\n",
                "print(f'\\nSample of recommendations:')\n",
                "print(rec_df.head(10).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Key Takeaways\n",
                "\n",
                "From the missing value analysis, we can draw these conclusions:\n",
                "\n",
                "1. **Missingness is structured, not random**: Features tend to be missing together in blocks and patterns\n",
                "\n",
                "2. **Missingness is predictive**: Some features show significant fraud rate differences based on presence or absence\n",
                "\n",
                "3. **Create indicators before imputing**: Binary `feature_missing` flags preserve valuable signal that would be lost\n",
                "\n",
                "4. **Tree models handle NaN**: LightGBM/XGBoost can handle missing values natively - test both impute and no-impute strategies\n",
                "\n",
                "### Professional Notes\n",
                "- Document imputation choices for production reproducibility\n",
                "- Compute imputation statistics on training data only to avoid leakage\n",
                "- Group correlated missingness patterns into single indicators for efficiency\n",
                "- Saved imputation strategy recommendations to `../data/metadata/missing_value_report.csv`\n",
                "\n",
                "---\n",
                "\n",
                "**Next:** `05_target_distribution_imbalance.ipynb`\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
