{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2827420d",
   "metadata": {},
   "source": [
    "## Context \n",
    "\n",
    "raw features capture the full predictive signal in the data. FE transfroms domain knowledge into model inputs. creating new perspectives on the data that can imporve model performance significanly\n",
    "\n",
    "## objective \n",
    "\n",
    "- create time-derived features from TransactionDT\n",
    "- build card-level based on address level aggregation features\n",
    "- engginer email domain and interaction features\n",
    "-  document transformation logic for profuction reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36314bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: (590540, 434)\n"
     ]
    }
   ],
   "source": [
    "# import and load data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "train = pd.read_parquet(Path('../data/interim/train_merged.parquet'))\n",
    "print(f'Data loaded: {train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9751b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time features created : \n",
      "                count       mean       std  min  25%   50%   75%   max\n",
      "hour         590540.0  13.861923  7.607152  0.0  6.0  16.0  20.0  23.0\n",
      "day_of_week  590540.0   2.928123  1.947733  0.0  1.0   3.0   5.0   6.0\n",
      "is_night     590540.0   0.378897  0.485113  0.0  0.0   0.0   1.0   1.0\n",
      "is_weekend   590540.0   0.254101  0.435355  0.0  0.0   0.0   1.0   1.0\n"
     ]
    }
   ],
   "source": [
    "# time features \n",
    "\n",
    "START_DATE = pd.Timestamp('2017-11-30')\n",
    "train['TransactionDate'] = START_DATE + pd.to_timedelta(train['TransactionDT'], unit='s')\n",
    "\n",
    "train['hour'] = train['TransactionDate'].dt.hour\n",
    "train['day_of_week'] = train['TransactionDate'].dt.dayofweek\n",
    "train['day_of_month'] = train['TransactionDate'].dt.day\n",
    "train['is_night'] = train['hour'].apply(lambda x : 1 if x >= 22 or x <= 5 else 0)\n",
    "train['is_weekend'] = train['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "print('Time features created : ')\n",
    "print(train[['hour', 'day_of_week', 'is_night', 'is_weekend']].describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e82b6",
   "metadata": {},
   "source": [
    "## insight : time based feature engginering\n",
    "\n",
    "from the result we have created these essential time features:\n",
    "- hour : hour of day 00-23. fraud rates peak during night hours\n",
    "- day_of_week : 0= monday to 6 = sunday. weekend patterns differ from weekdays\n",
    "- is_night : binary flag for 10 P.M to 5 A.M transaction when fraud is elevated\n",
    "- is_weekend : binary flag for saturday and sunday transactions\n",
    "\n",
    "these simple features consistenly rank in the top 50 by importance in tree models, providing high value for low engginering cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "345ffb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Features :\n",
      "       TransactionAmt  TransactionAmt_log  TransactionAmt_decimal  \\\n",
      "count   590540.000000       590540.000000           590540.000000   \n",
      "mean       135.027161            4.382960                0.379452   \n",
      "std        239.162521            0.937183                0.434118   \n",
      "min          0.251000            0.223943                0.000000   \n",
      "25%         43.320999            3.791459                0.000000   \n",
      "50%         68.769001            4.245190                0.000000   \n",
      "75%        125.000000            4.836282                0.949997   \n",
      "max      31937.390625           10.371564                0.999001   \n",
      "\n",
      "       is_round_amount  \n",
      "count    590540.000000  \n",
      "mean          0.516498  \n",
      "std           0.499728  \n",
      "min           0.000000  \n",
      "25%           0.000000  \n",
      "50%           1.000000  \n",
      "75%           1.000000  \n",
      "max           1.000000  \n"
     ]
    }
   ],
   "source": [
    "# AMOUNT FEATURES \n",
    "\n",
    "train['TransactionAmt_log'] = np.log1p(train['TransactionAmt'])\n",
    "train['TransactionAmt_decimal'] = train['TransactionAmt'] - train['TransactionAmt'].astype(int)\n",
    "train['is_round_amount'] = (train['TransactionAmt'] % 1 == 0).astype(int)\n",
    "\n",
    "print('Amount Features :')\n",
    "print(train[['TransactionAmt', 'TransactionAmt_log', 'TransactionAmt_decimal', 'is_round_amount']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc087c8a",
   "metadata": {},
   "source": [
    "## insight amount based feature engginering\n",
    "\n",
    "from the result we created amount based signals :\n",
    "\n",
    "- TransactionAmt_log : handles the extreme right skew in amount distribution\n",
    "- TransactionAmt_decimal : extract the decimal portion to detect .00 abd .99 pattern\n",
    "- is_round_amount : binary flah for whole dollar amounts which may indicate bot behavior\n",
    "\n",
    "Fraud patterns : very small amounts ( card testing) and round amounts ( automated transaction) correlate with higher fraud rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe04084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card aggregation features : \n",
      "       card1_amt_mean  card1_amt_std  card1_amt_count  amt_vs_card_mean\n",
      "count   590540.000000  587096.000000    590540.000000     590540.000000\n",
      "mean       135.027161     186.717651      2528.815464         -0.000001\n",
      "std         79.283325     130.683121      3702.655513        225.638794\n",
      "min          0.615000       0.000000         1.000000      -2297.212402\n",
      "25%         97.863770     100.616867       132.000000        -76.698120\n",
      "50%        120.209267     173.632751       919.000000        -33.817558\n",
      "75%        157.049408     235.915588      3152.000000          9.572350\n",
      "max       3454.949951    2648.284668     14932.000000      31657.542969\n"
     ]
    }
   ],
   "source": [
    "# card aggregations \n",
    "\n",
    "card_agg = train.groupby('card1')['TransactionAmt'].agg(['mean', 'std', 'count'])\n",
    "card_agg.columns = ['card1_amt_mean', 'card1_amt_std', 'card1_amt_count']\n",
    "\n",
    "# Drop existing columns if they exist to avoid merge conflicts\n",
    "cols_to_drop = [col for col in card_agg.columns if col in train.columns]\n",
    "train = train.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "train = train.merge(card_agg.reset_index(), on='card1', how='left')\n",
    "train['amt_vs_card_mean'] = train['TransactionAmt'] - train['card1_amt_mean']\n",
    "\n",
    "print('card aggregation features : ')\n",
    "print(train[['card1_amt_mean', 'card1_amt_std', 'card1_amt_count', 'amt_vs_card_mean']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd3c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email features : \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'email_match'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3801\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3802\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:153\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:182\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'email_match'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m train[\u001b[33m'\u001b[39m\u001b[33mR_email_is_free\u001b[39m\u001b[33m'\u001b[39m] = train[\u001b[33m'\u001b[39m\u001b[33mR_emaildomain\u001b[39m\u001b[33m'\u001b[39m].isin(free_emails).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33memail features : \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33memail match rate : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43memail_match\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4088\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4089\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4090\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4092\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3805\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3806\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3807\u001b[39m     ):\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3809\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3810\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3811\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3812\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3813\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'email_match'"
     ]
    }
   ],
   "source": [
    "free_emails = ['gmail.com', 'yahoo.com', 'hotmail.com', 'outlook.com', 'aol.com', 'icloud.com']\n",
    "train['P_email_is_free'] = train['P_emaildomain'].isin(free_emails).astype(int)\n",
    "train['R_email_is_free'] = train['R_emaildomain'].isin(free_emails).astype(int)\n",
    "\n",
    "print('email features : ')\n",
    "print(f'email match rate : {train['email_match']}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
